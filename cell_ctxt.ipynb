{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58c4708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for table 2 (post perturbation with full context w PCA compressed average control expression or AIDO control embeddings for cell line context)\n",
    "import torch\n",
    "import lightning as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from contextualized.easy import ContextualizedCorrelationNetworks\n",
    "import os\n",
    "\n",
    "from contextualized.regression.lightning_modules import ContextualizedCorrelation\n",
    "from contextualized.data import CorrelationDataModule\n",
    "from lightning import seed_everything, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07245d7",
   "metadata": {},
   "source": [
    "## Make Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e792cd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cell line context mode: embeddings\n",
      "\n",
      "AIDO embeddings context: Original dim 640, now 20D after scaling and PCA for 1 unique cells.\n",
      "Scaling continuous context features...\n",
      "Context scaling complete. Continuous features scaled: 22, Other features: 137, Total: 159\n",
      "\n",
      "Context matrix:   train (270, 159)   test (134, 159)\n",
      "Applying PCA to gene expression data...\n",
      "Gene expression data: Reduced to 50 PCs and Z-score normalized.\n"
     ]
    }
   ],
   "source": [
    "# expression for pca compressed avg control expression, embeddings for aido embeddings for cell line context\n",
    "\n",
    "# CONTEXT_MODE = 'expression' \n",
    "CONTEXT_MODE = 'embeddings' \n",
    "\n",
    "# File Paths\n",
    "PATH_L1000 = 'data/merged_output4_head.csv'\n",
    "PATH_CTLS = 'data/ctrls.csv'\n",
    "EMB_FILE = 'data/aido_cell_100m_lincs_embeddings.npy'\n",
    "\n",
    "N_DATA_PCS = 50    \n",
    "TEST_SIZE = 0.33\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "N_CTRL_PCS = 20\n",
    "N_EMBEDDING_PCS = 20 \n",
    "\n",
    "#specify type of perturbation to fit on\n",
    "pert_to_fit_on = ['trt_cp']\n",
    "\n",
    "\n",
    "# Validate file paths\n",
    "if not os.path.exists(PATH_L1000):\n",
    "    raise FileNotFoundError(f\"L1000 data not found at {PATH_L1000}\")\n",
    "if not os.path.exists(PATH_CTLS):\n",
    "    raise FileNotFoundError(f\"Controls data not found at {PATH_CTLS}\")\n",
    "if CONTEXT_MODE == 'embeddings' and not os.path.exists(EMB_FILE):\n",
    "    raise FileNotFoundError(f\"Embeddings file not found at {EMB_FILE}\")\n",
    "\n",
    "print(f\"Using cell line context mode: {CONTEXT_MODE}\\n\")\n",
    "\n",
    "# Load L1000 data\n",
    "df = pd.read_csv(PATH_L1000, engine='pyarrow')\n",
    "\n",
    "df = df[df['pert_type'].isin(pert_to_fit_on)]\n",
    "\n",
    "# Quality filters\n",
    "bad = (\n",
    "    (df['distil_cc_q75'] < 0.2) | (df['distil_cc_q75'] == -666) | (df['distil_cc_q75'].isna()) |\n",
    "    (df['pct_self_rank_q25'] > 5) | (df['pct_self_rank_q25'] == -666) | (df['pct_self_rank_q25'].isna())\n",
    ")\n",
    "df = df[~bad]\n",
    "\n",
    "# Ignore-flag columns for missing meta-data\n",
    "df['ignore_flag_pert_time'] = (df['pert_time'] == -666).astype(int)\n",
    "df['ignore_flag_pert_dose'] = (df['pert_dose'] == -666).astype(int)\n",
    "\n",
    "# Replace –666 with column mean\n",
    "for col in ['pert_time', 'pert_dose']:\n",
    "    mean_val = df.loc[df[col] != -666, col].mean()\n",
    "    df[col] = df[col].replace(-666, mean_val)\n",
    "\n",
    "# Get X (gene expression data)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "drop_cols = ['pert_dose', 'pert_dose_unit', 'pert_time',\n",
    "             'distil_cc_q75', 'pct_self_rank_q25']\n",
    "feature_cols = [c for c in numeric_cols if c not in drop_cols]\n",
    "X_raw = df[feature_cols].values\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X_raw)  # shape (N, p)\n",
    "\n",
    "# Get context components\n",
    "pert_dummies = pd.get_dummies(df['pert_id'], drop_first=True)\n",
    "\n",
    "pert_time = df['pert_time'].to_numpy().reshape(-1, 1)\n",
    "pert_dose = df['pert_dose'].to_numpy().reshape(-1, 1)\n",
    "ignore_time = df['ignore_flag_pert_time'].to_numpy().reshape(-1, 1)\n",
    "ignore_dose = df['ignore_flag_pert_dose'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "\n",
    "cell2vec = {}\n",
    "unique_cells_in_l1000 = np.sort(df['cell_id'].unique())\n",
    "\n",
    "if CONTEXT_MODE == 'expression':\n",
    "    print(\"Preparing cell line context using PCA of control expression...\")\n",
    "    ctrls_df = pd.read_csv(PATH_CTLS, index_col=0)  # index = cell_id\n",
    "    \n",
    "    # Filter controls to only include cells present in the L1000 dataset\n",
    "    ctrls_df = ctrls_df.loc[ctrls_df.index.intersection(unique_cells_in_l1000)]\n",
    "    \n",
    "    if ctrls_df.empty:\n",
    "        raise ValueError(\"No common cell IDs found between lincs1000.csv and ctrls.csv for PCA control expression.\")\n",
    "\n",
    "    scaler_ctrls = StandardScaler()\n",
    "    ctrls_scaled = scaler_ctrls.fit_transform(ctrls_df.values)\n",
    "\n",
    "    n_cells = ctrls_scaled.shape[0]\n",
    "    n_components_for_context = min(N_CTRL_PCS, n_cells)\n",
    "\n",
    "    pca_ctrls = PCA(n_components=n_components_for_context, random_state=RANDOM_STATE)\n",
    "    ctrls_pcs = pca_ctrls.fit_transform(ctrls_scaled)  # shape (#cells, N_CTRL_PCS)\n",
    "\n",
    "    cell2vec = dict(zip(ctrls_df.index, ctrls_pcs))\n",
    "\n",
    "elif CONTEXT_MODE == 'embeddings':\n",
    "    all_embeddings_raw = np.load(EMB_FILE)\n",
    "\n",
    "    # Use ctrls.csv to map embedding rows to cell IDs\n",
    "    ctrls_meta_df = pd.read_csv(PATH_CTLS, index_col=0)\n",
    "    embedding_cell_ids_full = ctrls_meta_df.index.to_numpy()\n",
    "\n",
    "    if len(embedding_cell_ids_full) != all_embeddings_raw.shape[0]:\n",
    "        raise ValueError(\n",
    "            f\"Mismatch: embeddings file '{EMB_FILE}' has {all_embeddings_raw.shape[0]} entries, \"\n",
    "            f\"but ctrls.csv has {len(embedding_cell_ids_full)} cell IDs. \"\n",
    "            \"Please ensure they correspond row-wise.\"\n",
    "        )\n",
    "\n",
    "    # Z-score normalize embeddings\n",
    "    scaler_embeddings = StandardScaler()\n",
    "    embeddings_scaled = scaler_embeddings.fit_transform(all_embeddings_raw)\n",
    "\n",
    "    # Apply PCA to embeddings\n",
    "    n_embeddings_dim = embeddings_scaled.shape[1]\n",
    "    n_components_for_context = min(N_EMBEDDING_PCS, n_embeddings_dim)\n",
    "\n",
    "    pca_embeddings = PCA(n_components=n_components_for_context, random_state=RANDOM_STATE)\n",
    "    embeddings_pcs = pca_embeddings.fit_transform(embeddings_scaled)\n",
    "\n",
    "    # Create a mapping from cell_id to its processed embedding vector for all loaded embeddings\n",
    "    full_cell_embedding_map = dict(zip(embedding_cell_ids_full, embeddings_pcs))\n",
    "\n",
    "    # Filter to only include cells present in the L1000 dataset\n",
    "    for cell_id in unique_cells_in_l1000:\n",
    "        if cell_id in full_cell_embedding_map:\n",
    "            cell2vec[cell_id] = full_cell_embedding_map[cell_id]\n",
    "\n",
    "    if not cell2vec:\n",
    "        raise ValueError(\n",
    "            \"No common cell IDs found between lincs1000.csv and embeddings/ctrls.csv. \"\n",
    "            \"Cannot proceed. Please check your data files.\"\n",
    "        )\n",
    "\n",
    "    print(f\"AIDO embeddings context: Original dim {n_embeddings_dim}, \"\n",
    "          f\"now {n_components_for_context}D after scaling and PCA for {len(cell2vec)} unique cells.\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Invalid CONTEXT_MODE: {CONTEXT_MODE}. Choose 'expression' or 'embeddings'.\")\n",
    "\n",
    "# Update the list of unique cells to process, based on what's available in cell2vec\n",
    "unique_cells = np.sort(list(cell2vec.keys()))\n",
    "\n",
    "if not unique_cells.shape[0] > 0:\n",
    "    raise RuntimeError(\"No cell IDs found to process after context loading and filtering. Check data consistency.\")\n",
    "\n",
    "continuous_context_list = []\n",
    "other_context_list = []\n",
    "cell_ids = df['cell_id'].to_numpy()\n",
    "\n",
    "for cell_id in unique_cells:\n",
    "    mask = cell_ids == cell_id\n",
    "    if mask.sum() == 0:\n",
    "        continue\n",
    "        \n",
    "    if mask.sum() < 2:  # At least 2 samples needed for a train/test split\n",
    "        print(f\"Skipping cell {cell_id} due to insufficient samples ({mask.sum()}). Needs at least 2 for split.\")\n",
    "        continue\n",
    "\n",
    "    # Continuous context features: cell context + pert_time + pert_dose\n",
    "    continuous_context = np.hstack([\n",
    "        np.tile(cell2vec[cell_id], (mask.sum(), 1)),  # Cell-specific context (PCA of expr or embeddings)\n",
    "        pert_time[mask],                              \n",
    "        pert_dose[mask],                              \n",
    "    ])\n",
    "    \n",
    "    # Other (categorical/binary) context features\n",
    "    other_context = np.hstack([\n",
    "        pert_dummies.loc[mask].values,                # Perturbation ID (one-hot encoded)\n",
    "        ignore_time[mask],                            \n",
    "        ignore_dose[mask],                            \n",
    "    ])\n",
    "    \n",
    "    continuous_context_list.append(continuous_context)\n",
    "    other_context_list.append(other_context)\n",
    "\n",
    "# Concatenate all continuous context features across cells\n",
    "all_continuous_context = np.vstack(continuous_context_list)\n",
    "all_other_context = np.vstack(other_context_list)\n",
    "\n",
    "# Scale the continuous context features together\n",
    "print(\"Scaling continuous context features...\")\n",
    "scaler_continuous_context = StandardScaler()\n",
    "all_continuous_context_scaled = scaler_continuous_context.fit_transform(all_continuous_context)\n",
    "\n",
    "# Combine scaled continuous context with other context features\n",
    "all_context_scaled = np.hstack([all_continuous_context_scaled, all_other_context])\n",
    "\n",
    "print(f\"Context scaling complete. Continuous features scaled: {all_continuous_context.shape[1]}, \"\n",
    "      f\"Other features: {all_other_context.shape[1]}, Total: {all_context_scaled.shape[1]}\")\n",
    "\n",
    "# Now split the data\n",
    "X_tr_lst, X_te_lst = [], []\n",
    "C_tr_lst, C_te_lst = [], []\n",
    "cell_tr_lst, cell_te_lst = [], []\n",
    "\n",
    "start_idx = 0\n",
    "for i, cell_id in enumerate(unique_cells):\n",
    "    mask = cell_ids == cell_id\n",
    "    if mask.sum() == 0:\n",
    "        continue\n",
    "        \n",
    "    if mask.sum() < 2:\n",
    "        continue\n",
    "\n",
    "    end_idx = start_idx + mask.sum()\n",
    "    \n",
    "    X_cell = X_scaled[mask]\n",
    "    C_cell = all_context_scaled[start_idx:end_idx]\n",
    "    ids_cell = cell_ids[mask]\n",
    "    \n",
    "    X_tr, X_te, C_tr, C_te, ids_tr, ids_te = train_test_split(\n",
    "        X_cell, C_cell, ids_cell,\n",
    "        test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    X_tr_lst.append(X_tr)\n",
    "    X_te_lst.append(X_te)\n",
    "    C_tr_lst.append(C_tr)\n",
    "    C_te_lst.append(C_te)\n",
    "    cell_tr_lst.append(ids_tr)\n",
    "    cell_te_lst.append(ids_te)\n",
    "    \n",
    "    start_idx = end_idx\n",
    "\n",
    "if not X_tr_lst or not X_te_lst:\n",
    "    raise RuntimeError(\n",
    "        \"No data collected for training/testing after splits. \"\n",
    "        \"This might be due to all cells being filtered or having insufficient samples.\"\n",
    "    )\n",
    "\n",
    "# Concatenate splits across cells\n",
    "X_train = np.vstack(X_tr_lst)\n",
    "X_test = np.vstack(X_te_lst)\n",
    "C_train = np.vstack(C_tr_lst)\n",
    "C_test = np.vstack(C_te_lst)\n",
    "cell_ids_train = np.concatenate(cell_tr_lst)\n",
    "cell_ids_test = np.concatenate(cell_te_lst)\n",
    "\n",
    "print(f'\\nContext matrix:   train {C_train.shape}   test {C_test.shape}')\n",
    "\n",
    "# Do any extra processing based on train split\n",
    "# --- PCA on Gene Expression Data (X) ---\n",
    "print(\"Applying PCA to gene expression data...\")\n",
    "pca_data = PCA(n_components=N_DATA_PCS, random_state=RANDOM_STATE)\n",
    "X_train_pca = pca_data.fit_transform(X_train)\n",
    "X_test_pca = pca_data.transform(X_test)\n",
    "\n",
    "# Z-score in latent space\n",
    "mu, sigma = X_train_pca.mean(0), X_train_pca.std(0)\n",
    "X_train_norm = (X_train_pca - mu) / sigma\n",
    "X_test_norm = (X_test_pca - mu) / sigma\n",
    "print(f\"Gene expression data: Reduced to {N_DATA_PCS} PCs and Z-score normalized.\")\n",
    "\n",
    "# Set useful variables\n",
    "train_group_ids = cell_ids_train\n",
    "test_group_ids = cell_ids_test\n",
    "C_train = C_train\n",
    "C_test = C_test\n",
    "X_train = X_train_norm\n",
    "X_test = X_test_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7358b87",
   "metadata": {},
   "source": [
    "## Fit Population Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4736b20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.980000000000001\n",
      "Test MSE: 0.39288096437129766\n"
     ]
    }
   ],
   "source": [
    "from contextualized.baselines.networks import CorrelationNetwork\n",
    "pop_model = CorrelationNetwork()\n",
    "pop_model.fit(X_train)\n",
    "print(f\"Train MSE: {pop_model.measure_mses(X_train).mean()}\")\n",
    "print(f\"Test MSE: {pop_model.measure_mses(X_test).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62f2d2c",
   "metadata": {},
   "source": [
    "## Fit Grouped Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fd5dd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped Train MSE: 0.980000000000001\n",
      "Grouped Test MSE: 0.39288096437129766\n"
     ]
    }
   ],
   "source": [
    "from contextualized.baselines.networks import GroupedNetworks\n",
    "grouped_model = GroupedNetworks(CorrelationNetwork)\n",
    "grouped_model.fit(X_train, train_group_ids)\n",
    "print(f\"Grouped Train MSE: {grouped_model.measure_mses(X_train, train_group_ids).mean()}\")\n",
    "print(f\"Grouped Test MSE: {grouped_model.measure_mses(X_test, test_group_ids).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4098cf",
   "metadata": {},
   "source": [
    "## Fit Contextualized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a85bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/calebellington/.netrc\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>logs/wandb/run-20250713_124618-mqse2awo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fm4bio/contextpert/runs/mqse2awo' target=\"_blank\">cell_line_context</a></strong> to <a href='https://wandb.ai/fm4bio/contextpert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fm4bio/contextpert' target=\"_blank\">https://wandb.ai/fm4bio/contextpert</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fm4bio/contextpert/runs/mqse2awo' target=\"_blank\">https://wandb.ai/fm4bio/contextpert/runs/mqse2awo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | metamodel | SubtypeMetamodel | 255 K  | train\n",
      "-------------------------------------------------------\n",
      "255 K     Trainable params\n",
      "0         Non-trainable params\n",
      "255 K     Total params\n",
      "1.021     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/contextpert/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/contextpert/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/contextpert/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 9/9 [00:00<00:00, 23.63it/s, v_num=2awo] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 9/9 [00:00<00:00, 22.99it/s, v_num=2awo]\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key='add-your-key-here')  # Add your WandB API key here\n",
    "\n",
    "contextualized_model = ContextualizedCorrelation(\n",
    "    context_dim=C_train.shape[1],\n",
    "    x_dim=X_train.shape[1],\n",
    "    encoder_type='mlp',\n",
    "    num_archetypes=50,\n",
    ")\n",
    "# Random val split\n",
    "C_val = train_test_split(C_train, test_size=0.2, random_state=RANDOM_STATE)[0]\n",
    "X_val = train_test_split(X_train, test_size=0.2, random_state=RANDOM_STATE)[0]\n",
    "datamodule = CorrelationDataModule(\n",
    "    C_train=C_train,\n",
    "    X_train=X_train,\n",
    "    C_val=C_val,\n",
    "    X_val=X_val,\n",
    "    C_test=C_test,\n",
    "    X_test=X_test,\n",
    "    C_predict=np.concatenate((C_train, C_test), axis=0),\n",
    "    X_predict=np.concatenate((X_train, X_test), axis=0),\n",
    "    batch_size=32,\n",
    ")\n",
    "checkpoint_callback = pl.pytorch.callbacks.ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_top_k=1,\n",
    "    filename='best_model',\n",
    ")\n",
    "logger = pl.pytorch.loggers.WandbLogger(\n",
    "    project='contextpert',\n",
    "    name='cell_line_context',\n",
    "    log_model=True,\n",
    "    save_dir='logs/',\n",
    ")\n",
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='auto',\n",
    "    devices='auto',\n",
    "    callbacks=[checkpoint_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "trainer.fit(contextualized_model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "811a077e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model on training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/contextpert/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/contextpert/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 147.98it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9736742973327637\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Testing model on test data...\n",
      "Testing DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 95.69it/s] \n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.39202195405960083\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.39202195405960083}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Testing model on training data...\")\n",
    "trainer.test(contextualized_model, datamodule.train_dataloader())\n",
    "print(f\"Testing model on test data...\")\n",
    "trainer.test(contextualized_model, datamodule.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ea77354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/contextpert/mqse2awo/checkpoints/best_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca887966",
   "metadata": {},
   "source": [
    "## Predict Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec9f7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/contextpert/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/contextpert/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:  54%|█████▍    | 7/13 [00:00<00:00, 11.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calebellington/Workbench/contextpert/Contextualized/contextualized/regression/lightning_modules.py:785: MPS: nonzero op is supported natively starting from macOS 14.0. Falling back on CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Indexing.mm:404.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 16.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Necessary to save predictions from multiple devices in parallel\n",
    "from contextualized.callbacks import PredictionWriter\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(checkpoint_callback.best_model_path).parent / 'predictions'\n",
    "writer_callback = PredictionWriter(\n",
    "    output_dir=output_dir,\n",
    "    write_interval='batch',\n",
    ")\n",
    "trainer = Trainer(\n",
    "    accelerator='auto',\n",
    "    devices='auto',\n",
    "    callbacks=[checkpoint_callback, writer_callback],\n",
    ")\n",
    "_ = trainer.predict(contextualized_model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "477826f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile distributed predictions and put into order\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "# Convert context to hashable type for lookup\n",
    "C_train_hashable = [tuple(row) for row in C_train]\n",
    "C_test_hashable = [tuple(row) for row in C_test]\n",
    "\n",
    "# Gather preds and move to CPU\n",
    "all_correlations = {}\n",
    "all_betas = {}\n",
    "all_mus = {}\n",
    "pred_files = glob.glob(str(output_dir / 'predictions_*.pt'))\n",
    "for file in pred_files:\n",
    "    preds = torch.load(file)\n",
    "    for context, correlation, beta, mu in zip(preds['contexts'], preds['correlations'], preds['betas'], preds['mus']):\n",
    "        context_tuple = tuple(context.tolist())\n",
    "        all_correlations[context_tuple] = correlation.cpu().numpy()\n",
    "        all_betas[context_tuple] = beta.cpu().numpy()\n",
    "        all_mus[context_tuple] = mu.cpu().numpy()\n",
    "\n",
    "# Remake preds in order of C_train and C_test\n",
    "correlations_train = np.array([all_correlations[c] for c in C_train_hashable])\n",
    "correlations_test = np.array([all_correlations[c] for c in C_test_hashable])\n",
    "betas_train = np.array([all_betas[c] for c in C_train_hashable])\n",
    "betas_test = np.array([all_betas[c] for c in C_test_hashable])\n",
    "mus_train = np.array([all_mus[c] for c in C_train_hashable])\n",
    "mus_test = np.array([all_mus[c] for c in C_test_hashable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9f747da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSEs: 0.9736743374936839\n",
      "Test MSEs: 0.3920219624105609\n"
     ]
    }
   ],
   "source": [
    "# Get individual MSEs by sample\n",
    "# Sanity check: These should closely match the trainer.test() outputs from earlier\n",
    "def measure_mses(betas, mus, X):\n",
    "    mses = np.zeros(len(X))\n",
    "    for i in range(len(X)):\n",
    "        sample_mse = 0\n",
    "        for j in range(X.shape[-1]):\n",
    "            for k in range(X.shape[-1]):\n",
    "                residual = X[i, j] - betas[i, j, k] * X[i, k] - mus[i, j, k]\n",
    "                sample_mse += residual**2 / (X.shape[-1] ** 2)\n",
    "        mses += sample_mse / len(X)\n",
    "    return mses\n",
    "\n",
    "mse_train = measure_mses(betas_train, mus_train, X_train)\n",
    "mse_test = measure_mses(betas_test, mus_test, X_test)\n",
    "print(f\"Train MSEs: {mse_train.mean()}\")\n",
    "print(f\"Test MSEs: {mse_test.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "439abde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-cell MSE:\n",
      "Cell A375           :  train MSE =  0.9737   test MSE =  0.3920   (n=270/134)\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the unique cells that were included in the splits for per-cell MSE\n",
    "print(\"Per-cell MSE:\")\n",
    "for cell_id in unique_cells:\n",
    "    tr_mask = cell_ids_train == cell_id\n",
    "    te_mask = cell_ids_test == cell_id\n",
    "\n",
    "    if tr_mask.sum() == 0 and te_mask.sum() == 0:\n",
    "        continue\n",
    "\n",
    "    tr_mse = mse_train[tr_mask].mean() if tr_mask.any() else np.nan\n",
    "    te_mse = mse_test[te_mask].mean() if te_mask.any() else np.nan\n",
    "    print(f'Cell {cell_id:<15}:  train MSE = {tr_mse:7.4f}   '\n",
    "          f'test MSE = {te_mse:7.4f}   (n={tr_mask.sum():3d}/{te_mask.sum():3d})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11fd32c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contextpert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
