{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for table 3 (generalizing to unseen small molecule perturbations - cell expression as cell line context, fingerprint for pert context)\n",
    "\n",
    "import torch\n",
    "import lightning as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "# from contextualized.easy import ContextualizedCorrelationNetworks\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "import warnings\n",
    "\n",
    "from contextualized.regression.lightning_modules import ContextualizedCorrelation\n",
    "from contextualized.data import CorrelationDataModule\n",
    "from lightning import seed_everything, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Configuration and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 427 samples with valid SMILES...\n",
      "Found 144 unique perturbations (SMILES)\n",
      "Perturbation split: 115 train, 29 test perturbations\n",
      "Sample split: 340 train, 87 test samples\n"
     ]
    }
   ],
   "source": [
    "PATH_L1000   = 'data/trt_cp_smiles_head.csv' #file filtered with only the trt_cp perts with smiles\n",
    "PATH_CTLS    = 'data/ctrls.csv'     \n",
    "N_DATA_PCS   = 50   \n",
    "PERTURBATION_HOLDOUT_SIZE = 0.2  \n",
    "RANDOM_STATE = 42\n",
    "SUBSAMPLE_FRACTION = None  # None for using full data, or decimal for percent subsample\n",
    "\n",
    "morgan_gen = rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=4096)  \n",
    "\n",
    "# Function to generate Morgan fingerprints from SMILES\n",
    "def smiles_to_morgan_fp(smiles, generator=morgan_gen):\n",
    "    \"\"\"\n",
    "    Convert SMILES string to Morgan fingerprint using MorganGenerator.\n",
    "    \n",
    "    Args:\n",
    "        smiles (str): SMILES string\n",
    "        generator: RDKit MorganGenerator instance\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Binary fingerprint array, or array of zeros if invalid SMILES\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            warnings.warn(f\"Invalid SMILES: {smiles}\")\n",
    "            return np.zeros(generator.GetOptions().fpSize)\n",
    "        \n",
    "        fp = generator.GetFingerprint(mol)\n",
    "        return np.array(fp)\n",
    "        # return np.zeros(generator.GetOptions().fpSize)\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Error processing SMILES {smiles}: {str(e)}\")\n",
    "        return np.zeros(generator.GetOptions().fpSize)\n",
    "\n",
    "#load data\n",
    "df = pd.read_csv(PATH_L1000, engine='pyarrow')\n",
    "\n",
    "# pick the perturbation to fit model on here\n",
    "pert_to_fit_on = ['trt_cp']\n",
    "df = df[df['pert_type'].isin(pert_to_fit_on)]\n",
    "\n",
    "# quality filters\n",
    "bad = (\n",
    "    (df['distil_cc_q75'] < 0.2) | (df['distil_cc_q75'] == -666) | (df['distil_cc_q75'].isna()) |\n",
    "    (df['pct_self_rank_q25'] > 5) | (df['pct_self_rank_q25'] == -666) | (df['pct_self_rank_q25'].isna())\n",
    ")\n",
    "df = df[~bad]\n",
    "\n",
    "# Filter out samples with missing SMILES\n",
    "df = df.dropna(subset=['canonical_smiles'])\n",
    "df = df[df['canonical_smiles'] != '']\n",
    "\n",
    "print(f\"Processing {len(df)} samples with valid SMILES...\")\n",
    "\n",
    "if SUBSAMPLE_FRACTION is not None:\n",
    "    df = df.sample(frac=SUBSAMPLE_FRACTION, random_state=RANDOM_STATE)\n",
    "    print(f\"Subsampled to {len(df)} samples ({SUBSAMPLE_FRACTION*100}% of data)\")\n",
    "\n",
    "# PERTURBATION HOLDOUT: Split unique perturbations first\n",
    "unique_smiles = df['canonical_smiles'].unique()\n",
    "print(f\"Found {len(unique_smiles)} unique perturbations (SMILES)\")\n",
    "\n",
    "# Split unique SMILES into train and test sets\n",
    "smiles_train, smiles_test = train_test_split(\n",
    "    unique_smiles, \n",
    "    test_size=PERTURBATION_HOLDOUT_SIZE, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Perturbation split: {len(smiles_train)} train, {len(smiles_test)} test perturbations\")\n",
    "\n",
    "# Create train and test dataframes based on perturbation split\n",
    "df_train = df[df['canonical_smiles'].isin(smiles_train)].copy()\n",
    "df_test = df[df['canonical_smiles'].isin(smiles_test)].copy()\n",
    "\n",
    "print(f\"Sample split: {len(df_train)} train, {len(df_test)} test samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Morgan fingerprints for train set...\n",
      "Generated Morgan fingerprints for train: shape (340, 4096)\n",
      "Generating Morgan fingerprints for test set...\n",
      "Generated Morgan fingerprints for test: shape (87, 4096)\n",
      "Applying improved scaling strategy...\n",
      "Gene expression scaled: train (340, 983), test (87, 983)\n",
      "Morgan fingerprints scaled: train (340, 4096), test (87, 4096)\n",
      "Loaded and processed control embeddings for 1 unique cells.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mmfs1/gscratch/ark/jiaqi/miniconda3/envs/cml/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n"
     ]
    }
   ],
   "source": [
    "# Process train/test sets - fit preprocessing on training data only\n",
    "pert_time_mean = None\n",
    "pert_dose_mean = None\n",
    "\n",
    "for df_split, split_name in [(df_train, 'train'), (df_test, 'test')]:\n",
    "    # ignore-flag columns for missing meta-data\n",
    "    df_split['ignore_flag_pert_time'] = (df_split['pert_time'] == -666).astype(int)\n",
    "    df_split['ignore_flag_pert_dose'] = (df_split['pert_dose'] == -666).astype(int)\n",
    "\n",
    "    # replace –666 with column mean (computed from training set only)\n",
    "    for col in ['pert_time', 'pert_dose']:\n",
    "        if split_name == 'train':\n",
    "            mean_val = df_split.loc[df_split[col] != -666, col].mean()\n",
    "            # Store the mean for use with val/test sets\n",
    "            if col == 'pert_time':\n",
    "                pert_time_mean = mean_val\n",
    "            else:\n",
    "                pert_dose_mean = mean_val\n",
    "        else:\n",
    "            # Use training set means for test set\n",
    "            mean_val = pert_time_mean if col == 'pert_time' else pert_dose_mean\n",
    "        \n",
    "        df_split[col] = df_split[col].replace(-666, mean_val)\n",
    "\n",
    "# Function to process data split\n",
    "def process_data_split(df_split, split_name):\n",
    "    # Getting X (gene expression features)\n",
    "    numeric_cols   = df_split.select_dtypes(include=[np.number]).columns\n",
    "    drop_cols      = ['pert_dose', 'pert_dose_unit', 'pert_time',\n",
    "                      'distil_cc_q75', 'pct_self_rank_q25']\n",
    "    feature_cols   = [c for c in numeric_cols if c not in drop_cols]\n",
    "    X_raw          = df_split[feature_cols].values\n",
    "\n",
    "    # Generate Morgan fingerprints\n",
    "    print(f\"Generating Morgan fingerprints for {split_name} set...\")\n",
    "    morgan_fps = []\n",
    "    for smiles in df_split['canonical_smiles']:\n",
    "        fp = smiles_to_morgan_fp(smiles)\n",
    "        morgan_fps.append(fp)\n",
    "\n",
    "    morgan_fps = np.array(morgan_fps)\n",
    "    print(f\"Generated Morgan fingerprints for {split_name}: shape {morgan_fps.shape}\")\n",
    "\n",
    "    # Keep other context features\n",
    "    pert_unit_dummies  = pd.get_dummies(df_split['pert_dose_unit'], drop_first=True)\n",
    "\n",
    "    pert_time   = df_split['pert_time'  ].to_numpy().reshape(-1, 1)\n",
    "    pert_dose   = df_split['pert_dose'  ].to_numpy().reshape(-1, 1)\n",
    "    ignore_time = df_split['ignore_flag_pert_time'].to_numpy().reshape(-1, 1)\n",
    "    ignore_dose = df_split['ignore_flag_pert_dose'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "    return X_raw, morgan_fps, pert_unit_dummies, pert_time, pert_dose, ignore_time, ignore_dose\n",
    "\n",
    "# Process both splits\n",
    "X_raw_train, morgan_fps_train, pert_unit_dummies_train, pert_time_train, pert_dose_train, ignore_time_train, ignore_dose_train = process_data_split(df_train, 'train')\n",
    "X_raw_test, morgan_fps_test, pert_unit_dummies_test, pert_time_test, pert_dose_test, ignore_time_test, ignore_dose_test = process_data_split(df_test, 'test')\n",
    "\n",
    "print(\"Applying improved scaling strategy...\")\n",
    "\n",
    "# scaling\n",
    "scaler_genes = StandardScaler()\n",
    "X_train_scaled = scaler_genes.fit_transform(X_raw_train)\n",
    "X_test_scaled = scaler_genes.transform(X_raw_test)\n",
    "print(f\"Gene expression scaled: train {X_train_scaled.shape}, test {X_test_scaled.shape}\")\n",
    "\n",
    "scaler_morgan = StandardScaler()\n",
    "morgan_train_scaled = morgan_fps_train.astype(float)\n",
    "morgan_test_scaled = morgan_fps_test.astype(float)\n",
    "print(f\"Morgan fingerprints scaled: train {morgan_train_scaled.shape}, test {morgan_test_scaled.shape}\")\n",
    "\n",
    "# Load and process control data\n",
    "ctrls_df = pd.read_csv(PATH_CTLS, index_col=0)          # index = cell_id\n",
    "unique_cells_train = np.sort(df_train['cell_id'].unique())\n",
    "unique_cells_test = np.sort(df_test['cell_id'].unique())\n",
    "unique_cells_all = np.sort(np.union1d(unique_cells_train, unique_cells_test))\n",
    "\n",
    "ctrls_df = ctrls_df.loc[ctrls_df.index.intersection(unique_cells_all)]\n",
    "\n",
    "# Standardize controls and do PCA\n",
    "scaler_ctrls = StandardScaler()\n",
    "ctrls_scaled = scaler_ctrls.fit_transform(ctrls_df.values)\n",
    "\n",
    "n_cells = ctrls_scaled.shape[0]\n",
    "n_ctrl_pcs = min(50, n_cells)\n",
    "\n",
    "pca_ctrls = PCA(n_components=n_ctrl_pcs, random_state=RANDOM_STATE)\n",
    "ctrls_pcs = pca_ctrls.fit_transform(ctrls_scaled)        # shape (n_cells, n_ctrl_pcs)\n",
    "\n",
    "# Build mapping from cell_id → compressed control vector\n",
    "cell2vec = dict(zip(ctrls_df.index, ctrls_pcs))\n",
    "\n",
    "if not cell2vec:\n",
    "    raise ValueError(\n",
    "        \"No common cell IDs found between lincs1000.csv and embeddings/ctrls.csv. \"\n",
    "        \"Cannot proceed. Please check your data files.\"\n",
    "    )\n",
    "\n",
    "print(f\"Loaded and processed control embeddings for {len(cell2vec)} unique cells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Build Context Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building context matrices with improved scaling...\n",
      "Fitted context scaler on (340, 3) continuous context features\n",
      "Context matrix:   train (340, 4101)   test (87, 4101)\n",
      "Feature matrix:   train (340, 983)   test (87, 983)\n",
      "Applying PCA with improved scaling...\n",
      "Normalized PCA features: train (340, 50)   test (87, 50)\n"
     ]
    }
   ],
   "source": [
    "def build_context_matrix_improved(df_split, morgan_fps_scaled, pert_time, pert_dose, \n",
    "                                 ignore_time, ignore_dose, split_name, scaler_context=None, is_train=False):\n",
    "    \"\"\"\n",
    "    Build context matrix with globally consistent scaling\n",
    "    \"\"\"\n",
    "    cell_ids = df_split['cell_id'].to_numpy()\n",
    "    unique_cells_split = np.sort(df_split['cell_id'].unique())\n",
    "    \n",
    "    all_continuous_context = []\n",
    "    valid_cells = []\n",
    "    \n",
    "    for cell_id in unique_cells_split:\n",
    "        if cell_id not in cell2vec:\n",
    "            print(f\"Warning: Cell {cell_id} not found in control embeddings, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        mask = cell_ids == cell_id\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "            \n",
    "        valid_cells.append(cell_id)\n",
    "        \n",
    "        # Build continuous context matrix (cell embeddings + time + dose)\n",
    "        C_continuous = np.hstack([\n",
    "            np.tile(cell2vec[cell_id], (mask.sum(), 1)),  # Cell embeddings\n",
    "            pert_time[mask],                              # Perturbation time\n",
    "            pert_dose[mask],                              # Perturbation dose\n",
    "        ])\n",
    "        all_continuous_context.append(C_continuous)\n",
    "    \n",
    "    # Fit scaler on all continuous context (training data only)\n",
    "    if is_train:\n",
    "        all_continuous_combined = np.vstack(all_continuous_context)\n",
    "        scaler_context = StandardScaler()\n",
    "        scaler_context.fit(all_continuous_combined)\n",
    "        print(f\"Fitted context scaler on {all_continuous_combined.shape} continuous context features\")\n",
    "    \n",
    "    if scaler_context is None:\n",
    "        raise ValueError(\"scaler_context must be provided for non-training data\")\n",
    "    \n",
    "    X_lst, C_lst, cell_lst = [], [], []\n",
    "    \n",
    "    for i, cell_id in enumerate(valid_cells):\n",
    "        mask = cell_ids == cell_id\n",
    "        X_cell = X_train_scaled[mask] if split_name == 'train' else X_test_scaled[mask]\n",
    "        \n",
    "        # Scale continuous context consistently\n",
    "        C_continuous_scaled = scaler_context.transform(all_continuous_context[i])\n",
    "        \n",
    "        n_samples = mask.sum()\n",
    "        \n",
    "        # Combine all context features\n",
    "        C_cell = np.hstack([\n",
    "            C_continuous_scaled,                    # Scaled continuous features\n",
    "            morgan_fps_scaled[mask],               # Pre-scaled molecular features  \n",
    "            ignore_time[mask],                     # Binary flags (unscaled)\n",
    "            ignore_dose[mask],\n",
    "        ])\n",
    "\n",
    "        X_lst.append(X_cell)\n",
    "        C_lst.append(C_cell)\n",
    "        cell_lst.append(cell_ids[mask])\n",
    "\n",
    "    if not X_lst:\n",
    "        raise RuntimeError(f\"No data collected for {split_name} set.\")\n",
    "    \n",
    "    X_final = np.vstack(X_lst)\n",
    "    C_final = np.vstack(C_lst)\n",
    "    cell_ids_final = np.concatenate(cell_lst)\n",
    "    \n",
    "    return X_final, C_final, cell_ids_final, scaler_context\n",
    "\n",
    "# Build context matrices for both splits with improved scaling\n",
    "print(\"Building context matrices with improved scaling...\")\n",
    "\n",
    "X_train, C_train, cell_ids_train, scaler_context = build_context_matrix_improved(\n",
    "    df_train, morgan_train_scaled, pert_time_train, pert_dose_train,\n",
    "    ignore_time_train, ignore_dose_train, 'train', is_train=True\n",
    ")\n",
    "\n",
    "X_test, C_test, cell_ids_test, _ = build_context_matrix_improved(\n",
    "    df_test, morgan_test_scaled, pert_time_test, pert_dose_test,\n",
    "    ignore_time_test, ignore_dose_test, 'test', scaler_context=scaler_context\n",
    ")\n",
    "\n",
    "print(f'Context matrix:   train {C_train.shape}   test {C_test.shape}')\n",
    "print(f'Feature matrix:   train {X_train.shape}   test {X_test.shape}')\n",
    "\n",
    "# IMPROVED PCA WITH BETTER SCALING\n",
    "print(\"Applying PCA with improved scaling...\")\n",
    "\n",
    "# PCA on features (fit on training data only)\n",
    "pca_data = PCA(n_components=N_DATA_PCS, random_state=RANDOM_STATE)\n",
    "X_train_pca = pca_data.fit_transform(X_train)\n",
    "X_test_pca = pca_data.transform(X_test)\n",
    "\n",
    "# Improved scaling in PCA space\n",
    "pca_scaler = StandardScaler()\n",
    "X_train_norm = pca_scaler.fit_transform(X_train_pca)\n",
    "X_test_norm = pca_scaler.transform(X_test_pca)\n",
    "\n",
    "print(f'Normalized PCA features: train {X_train_norm.shape}   test {X_test_norm.shape}')\n",
    "\n",
    "# Set useful variables\n",
    "train_group_ids = cell_ids_train\n",
    "test_group_ids = cell_ids_test\n",
    "X_train = X_train_norm\n",
    "X_test = X_test_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Fit Population Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.9800000000000011\n",
      "Test MSE: 0.5395354454114102\n"
     ]
    }
   ],
   "source": [
    "from contextualized.baselines.networks import CorrelationNetwork\n",
    "pop_model = CorrelationNetwork()\n",
    "pop_model.fit(X_train)\n",
    "print(f\"Train MSE: {pop_model.measure_mses(X_train).mean()}\")\n",
    "print(f\"Test MSE: {pop_model.measure_mses(X_test).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Fit Grouped Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped Train MSE: 0.9800000000000011\n",
      "Grouped Test MSE: 0.5395354454114102\n"
     ]
    }
   ],
   "source": [
    "from contextualized.baselines.networks import GroupedNetworks\n",
    "grouped_model = GroupedNetworks(CorrelationNetwork)\n",
    "grouped_model.fit(X_train, train_group_ids)\n",
    "print(f\"Grouped Train MSE: {grouped_model.measure_mses(X_train, train_group_ids).mean()}\")\n",
    "print(f\"Grouped Test MSE: {grouped_model.measure_mses(X_test, test_group_ids).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Fit Contextualized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /mmfs1/home/jiaqiw18/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiaqiw\u001b[0m (\u001b[33mcontextualized\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "/mmfs1/gscratch/ark/jiaqi/miniconda3/envs/cml/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /mmfs1/gscratch/ark/jiaqi/miniconda3/envs/cml/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>logs/wandb/run-20250716_060220-dscn3fb5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/contextualized/contextpert/runs/dscn3fb5' target=\"_blank\">unseen_perturbations</a></strong> to <a href='https://wandb.ai/contextualized/contextpert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/contextualized/contextpert' target=\"_blank\">https://wandb.ai/contextualized/contextpert</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/contextualized/contextpert/runs/dscn3fb5' target=\"_blank\">https://wandb.ai/contextualized/contextpert/runs/dscn3fb5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | metamodel | SubtypeMetamodel | 253 K  | train\n",
      "-------------------------------------------------------\n",
      "253 K     Trainable params\n",
      "0         Non-trainable params\n",
      "253 K     Total params\n",
      "1.013     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                               "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mmfs1/gscratch/ark/jiaqi/miniconda3/envs/cml/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 81.43it/s, v_num=3fb5]\n",
      "Validation: |                                                                                                                                                                            | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                                                        | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                           | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|████████████████▏                                                                                                                                 | 1/9 [00:00<00:00, 129.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|████████████████████████████████▍                                                                                                                 | 2/9 [00:00<00:00, 148.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████████████████████████████████████████████████▋                                                                                                 | 3/9 [00:00<00:00, 160.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|████████████████████████████████████████████████████████████████▉                                                                                 | 4/9 [00:00<00:00, 166.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|█████████████████████████████████████████████████████████████████████████████████                                                                 | 5/9 [00:00<00:00, 171.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                                | 6/9 [00:00<00:00, 173.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 7/9 [00:00<00:00, 176.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 8/9 [00:00<00:00, 178.56it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 181.67it/s]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 162.65it/s, v_num=3fb5]\u001b[A\n",
      "Validation: |                                                                                                                                                                            | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                                                        | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                           | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|████████████████▏                                                                                                                                 | 1/9 [00:00<00:00, 128.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|████████████████████████████████▍                                                                                                                 | 2/9 [00:00<00:00, 152.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████████████████████████████████████████████████▋                                                                                                 | 3/9 [00:00<00:00, 164.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|████████████████████████████████████████████████████████████████▉                                                                                 | 4/9 [00:00<00:00, 171.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|█████████████████████████████████████████████████████████████████████████████████                                                                 | 5/9 [00:00<00:00, 175.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                                | 6/9 [00:00<00:00, 178.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 7/9 [00:00<00:00, 180.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 8/9 [00:00<00:00, 182.37it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 185.18it/s]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 164.84it/s, v_num=3fb5]\u001b[A\n",
      "Validation: |                                                                                                                                                                            | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                                                        | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                           | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|████████████████▏                                                                                                                                 | 1/9 [00:00<00:00, 128.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|████████████████████████████████▍                                                                                                                 | 2/9 [00:00<00:00, 105.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████████████████████████████████████████████████▋                                                                                                 | 3/9 [00:00<00:00, 124.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|████████████████████████████████████████████████████████████████▉                                                                                 | 4/9 [00:00<00:00, 136.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|█████████████████████████████████████████████████████████████████████████████████                                                                 | 5/9 [00:00<00:00, 145.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                                | 6/9 [00:00<00:00, 152.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 7/9 [00:00<00:00, 156.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 8/9 [00:00<00:00, 160.93it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 165.31it/s]\u001b[A\n",
      "Epoch 3: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 164.02it/s, v_num=3fb5]\u001b[A\n",
      "Validation: |                                                                                                                                                                            | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                                                        | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                           | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|████████████████▏                                                                                                                                 | 1/9 [00:00<00:00, 216.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|████████████████████████████████▍                                                                                                                 | 2/9 [00:00<00:00, 232.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████████████████████████████████████████████████▋                                                                                                 | 3/9 [00:00<00:00, 239.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|████████████████████████████████████████████████████████████████▉                                                                                 | 4/9 [00:00<00:00, 182.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|█████████████████████████████████████████████████████████████████████████████████                                                                 | 5/9 [00:00<00:00, 184.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                                | 6/9 [00:00<00:00, 186.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 7/9 [00:00<00:00, 187.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 8/9 [00:00<00:00, 188.82it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 191.61it/s]\u001b[A\n",
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 163.53it/s, v_num=3fb5]\u001b[A\n",
      "Validation: |                                                                                                                                                                            | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                                                        | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                           | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|████████████████▏                                                                                                                                 | 1/9 [00:00<00:00, 129.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|████████████████████████████████▍                                                                                                                 | 2/9 [00:00<00:00, 153.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████████████████████████████████████████████████▋                                                                                                 | 3/9 [00:00<00:00, 165.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|████████████████████████████████████████████████████████████████▉                                                                                 | 4/9 [00:00<00:00, 170.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|█████████████████████████████████████████████████████████████████████████████████                                                                 | 5/9 [00:00<00:00, 175.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                                | 6/9 [00:00<00:00, 178.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 7/9 [00:00<00:00, 181.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 8/9 [00:00<00:00, 182.56it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 185.79it/s]\u001b[A\n",
      "Epoch 5: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 164.07it/s, v_num=3fb5]\u001b[A\n",
      "Validation: |                                                                                                                                                                            | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                                                        | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                           | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|████████████████▏                                                                                                                                 | 1/9 [00:00<00:00, 126.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|████████████████████████████████▍                                                                                                                 | 2/9 [00:00<00:00, 150.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████████████████████████████████████████████████▋                                                                                                 | 3/9 [00:00<00:00, 162.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|████████████████████████████████████████████████████████████████▉                                                                                 | 4/9 [00:00<00:00, 168.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|█████████████████████████████████████████████████████████████████████████████████                                                                 | 5/9 [00:00<00:00, 173.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                                | 6/9 [00:00<00:00, 176.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 7/9 [00:00<00:00, 179.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 8/9 [00:00<00:00, 180.81it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 183.93it/s]\u001b[A\n",
      "Epoch 6: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 161.99it/s, v_num=3fb5]\u001b[A\n",
      "Validation: |                                                                                                                                                                            | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                                                        | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                           | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|████████████████▏                                                                                                                                 | 1/9 [00:00<00:00, 128.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|████████████████████████████████▍                                                                                                                 | 2/9 [00:00<00:00, 150.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████████████████████████████████████████████████▋                                                                                                 | 3/9 [00:00<00:00, 161.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|████████████████████████████████████████████████████████████████▉                                                                                 | 4/9 [00:00<00:00, 169.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|█████████████████████████████████████████████████████████████████████████████████                                                                 | 5/9 [00:00<00:00, 173.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                                | 6/9 [00:00<00:00, 176.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 7/9 [00:00<00:00, 178.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 8/9 [00:00<00:00, 180.17it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 183.03it/s]\u001b[A\n",
      "Epoch 7: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 163.29it/s, v_num=3fb5]\u001b[A\n",
      "Validation: |                                                                                                                                                                            | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                                                        | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                           | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|████████████████▏                                                                                                                                 | 1/9 [00:00<00:00, 128.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|████████████████████████████████▍                                                                                                                 | 2/9 [00:00<00:00, 151.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████████████████████████████████████████████████▋                                                                                                 | 3/9 [00:00<00:00, 162.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|████████████████████████████████████████████████████████████████▉                                                                                 | 4/9 [00:00<00:00, 169.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|█████████████████████████████████████████████████████████████████████████████████                                                                 | 5/9 [00:00<00:00, 173.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                                | 6/9 [00:00<00:00, 177.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 7/9 [00:00<00:00, 178.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 8/9 [00:00<00:00, 180.81it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 183.30it/s]\u001b[A\n",
      "Epoch 8: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 149.17it/s, v_num=3fb5]\u001b[A\n",
      "Validation: |                                                                                                                                                                            | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                                                        | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                           | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|████████████████▏                                                                                                                                 | 1/9 [00:00<00:00, 127.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|████████████████████████████████▍                                                                                                                 | 2/9 [00:00<00:00, 153.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████████████████████████████████████████████████▋                                                                                                 | 3/9 [00:00<00:00, 165.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|████████████████████████████████████████████████████████████████▉                                                                                 | 4/9 [00:00<00:00, 171.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|█████████████████████████████████████████████████████████████████████████████████                                                                 | 5/9 [00:00<00:00, 175.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                                | 6/9 [00:00<00:00, 177.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 7/9 [00:00<00:00, 180.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 8/9 [00:00<00:00, 182.01it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 185.08it/s]\u001b[A\n",
      "Epoch 9: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 163.46it/s, v_num=3fb5]\u001b[A\n",
      "Validation: |                                                                                                                                                                            | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                                                        | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                           | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|████████████████▏                                                                                                                                 | 1/9 [00:00<00:00, 128.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|████████████████████████████████▍                                                                                                                 | 2/9 [00:00<00:00, 153.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████████████████████████████████████████████████▋                                                                                                 | 3/9 [00:00<00:00, 164.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|████████████████████████████████████████████████████████████████▉                                                                                 | 4/9 [00:00<00:00, 170.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|█████████████████████████████████████████████████████████████████████████████████                                                                 | 5/9 [00:00<00:00, 175.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                                | 6/9 [00:00<00:00, 178.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 7/9 [00:00<00:00, 181.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 8/9 [00:00<00:00, 182.90it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 185.64it/s]\u001b[A\n",
      "Epoch 9: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 85.51it/s, v_num=3fb5]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 78.35it/s, v_num=3fb5]\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key='add-your-key-here')  # Add your WandB API key here\n",
    "\n",
    "contextualized_model = ContextualizedCorrelation(\n",
    "    context_dim=C_train.shape[1],\n",
    "    x_dim=X_train.shape[1],\n",
    "    encoder_type='mlp',\n",
    "    num_archetypes=30,\n",
    ")\n",
    "# Random val split\n",
    "C_val = train_test_split(C_train, test_size=0.2, random_state=RANDOM_STATE)[0]\n",
    "X_val = train_test_split(X_train, test_size=0.2, random_state=RANDOM_STATE)[0]\n",
    "datamodule = CorrelationDataModule(\n",
    "    C_train=C_train,\n",
    "    X_train=X_train,\n",
    "    C_val=C_val,\n",
    "    X_val=X_val,\n",
    "    C_test=C_test,\n",
    "    X_test=X_test,\n",
    "    C_predict=np.concatenate((C_train, C_test), axis=0),\n",
    "    X_predict=np.concatenate((X_train, X_test), axis=0),\n",
    "    batch_size=32,\n",
    ")\n",
    "checkpoint_callback = pl.pytorch.callbacks.ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_top_k=1,\n",
    "    filename='best_model',\n",
    ")\n",
    "logger = pl.pytorch.loggers.WandbLogger(\n",
    "    project='contextpert',\n",
    "    name='unseen_perturbations',\n",
    "    log_model=True,\n",
    "    save_dir='logs/',\n",
    ")\n",
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='auto',\n",
    "    devices='auto',\n",
    "    callbacks=[checkpoint_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "trainer.fit(contextualized_model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mmfs1/gscratch/ark/jiaqi/miniconda3/envs/cml/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /mmfs1/gscratch/ark/jiaqi/miniconda3/envs/cml/lib/py ...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/mmfs1/gscratch/ark/jiaqi/miniconda3/envs/cml/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model on training data...\n",
      "Testing DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 187.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8023610711097717\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Testing model on test data...\n",
      "Testing DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 232.87it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4427153170108795\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.4427153170108795}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Testing model on training data...\")\n",
    "trainer.test(contextualized_model, datamodule.train_dataloader())\n",
    "print(f\"Testing model on test data...\")\n",
    "trainer.test(contextualized_model, datamodule.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/contextpert/dscn3fb5/checkpoints/best_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Predict Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mmfs1/gscratch/ark/jiaqi/miniconda3/envs/cml/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /mmfs1/gscratch/ark/jiaqi/miniconda3/envs/cml/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/mmfs1/gscratch/ark/jiaqi/miniconda3/envs/cml/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Necessary to save predictions from multiple devices in parallel\n",
    "from contextualized.callbacks import PredictionWriter\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(checkpoint_callback.best_model_path).parent / 'predictions'\n",
    "writer_callback = PredictionWriter(\n",
    "    output_dir=output_dir,\n",
    "    write_interval='batch',\n",
    ")\n",
    "trainer = Trainer(\n",
    "    accelerator='auto',\n",
    "    devices='auto',\n",
    "    callbacks=[checkpoint_callback, writer_callback],\n",
    ")\n",
    "_ = trainer.predict(contextualized_model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile distributed predictions and put into order\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "# Convert context to hashable type for lookup\n",
    "C_train_hashable = [tuple(row) for row in C_train]\n",
    "C_test_hashable = [tuple(row) for row in C_test]\n",
    "\n",
    "# Gather preds and move to CPU\n",
    "all_correlations = {}\n",
    "all_betas = {}\n",
    "all_mus = {}\n",
    "pred_files = glob.glob(str(output_dir / 'predictions_*.pt'))\n",
    "for file in pred_files:\n",
    "    preds = torch.load(file)\n",
    "    for context, correlation, beta, mu in zip(preds['contexts'], preds['correlations'], preds['betas'], preds['mus']):\n",
    "        context_tuple = tuple(context.tolist())\n",
    "        all_correlations[context_tuple] = correlation.cpu().numpy()\n",
    "        all_betas[context_tuple] = beta.cpu().numpy()\n",
    "        all_mus[context_tuple] = mu.cpu().numpy()\n",
    "\n",
    "# Remake preds in order of C_train and C_test\n",
    "correlations_train = np.array([all_correlations[c] for c in C_train_hashable])\n",
    "correlations_test = np.array([all_correlations[c] for c in C_test_hashable])\n",
    "betas_train = np.array([all_betas[c] for c in C_train_hashable])\n",
    "betas_test = np.array([all_betas[c] for c in C_test_hashable])\n",
    "mus_train = np.array([all_mus[c] for c in C_train_hashable])\n",
    "mus_test = np.array([all_mus[c] for c in C_test_hashable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSEs: 0.7889181821196555\n",
      "Test MSEs: 0.4512621305680766\n",
      "\n",
      "Per-cell performance breakdown:\n",
      "Cell ID          Train MSE    Test MSE     Train N  Test N\n",
      "────────────────────────────────────────────────────────────\n",
      "A375               0.7889     0.4513      340       87\n",
      "\n",
      "================================================================================\n",
      "PERTURBATION HOLDOUT SUMMARY:\n",
      "  Total unique SMILES: 144\n",
      "  Training SMILES: 115 (79.9%)\n",
      "  Test SMILES: 29 (20.1%)\n",
      "  Training samples: 340\n",
      "  Test samples: 87\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Get individual MSEs by sample\n",
    "# Sanity check: These should closely match the trainer.test() outputs from earlier\n",
    "def measure_mses(betas, mus, X):\n",
    "    mses = np.zeros(len(X))\n",
    "    for i in range(len(X)):\n",
    "        sample_mse = 0\n",
    "        for j in range(X.shape[-1]):\n",
    "            for k in range(X.shape[-1]):\n",
    "                residual = X[i, j] - betas[i, j, k] * X[i, k] - mus[i, j, k]\n",
    "                sample_mse += residual**2 / (X.shape[-1] ** 2)\n",
    "        mses += sample_mse / len(X)\n",
    "    return mses\n",
    "\n",
    "mse_train = measure_mses(betas_train, mus_train, X_train)\n",
    "mse_test = measure_mses(betas_test, mus_test, X_test)\n",
    "print(f\"Train MSEs: {mse_train.mean()}\")\n",
    "print(f\"Test MSEs: {mse_test.mean()}\")\n",
    "\n",
    "# Per-cell performance breakdown\n",
    "print(f\"\\nPer-cell performance breakdown:\")\n",
    "print(\"Cell ID          Train MSE    Test MSE     Train N  Test N\")\n",
    "print(\"─\" * 60)\n",
    "\n",
    "all_unique_cells = np.union1d(cell_ids_train, cell_ids_test)\n",
    "\n",
    "for cell_id in sorted(all_unique_cells):\n",
    "    tr_mask = cell_ids_train == cell_id\n",
    "    te_mask = cell_ids_test == cell_id\n",
    "    \n",
    "    tr_mse = mse_train[tr_mask].mean() if tr_mask.any() else np.nan\n",
    "    te_mse = mse_test[te_mask].mean() if te_mask.any() else np.nan\n",
    "    tr_n = tr_mask.sum()\n",
    "    te_n = te_mask.sum()\n",
    "    \n",
    "    if tr_n > 0 or te_n > 0:\n",
    "        print(f'{cell_id:<15}  {tr_mse:8.4f}   {te_mse:8.4f}   {tr_n:6d}   {te_n:6d}')\n",
    "\n",
    "# Summary statistics about the perturbation split\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"PERTURBATION HOLDOUT SUMMARY:\")\n",
    "print(f\"  Total unique SMILES: {len(unique_smiles)}\")\n",
    "print(f\"  Training SMILES: {len(smiles_train)} ({len(smiles_train)/len(unique_smiles)*100:.1f}%)\")\n",
    "print(f\"  Test SMILES: {len(smiles_test)} ({len(smiles_test)/len(unique_smiles)*100:.1f}%)\")\n",
    "print(f\"  Training samples: {len(df_train)}\")\n",
    "print(f\"  Test samples: {len(df_test)}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
